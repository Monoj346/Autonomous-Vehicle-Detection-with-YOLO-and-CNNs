{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, BatchNormalization, Dropout\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def yolo_filter_boxes(boxes, conf, probs, thresh=0.6):\n",
    "    \"\"\"Filters YOLO boxes based on confidence and class scores.\"\"\"\n",
    "    \n",
    "    # Compute box scores\n",
    "    scores = probs * conf\n",
    "\n",
    "    # Get class with highest score & corresponding score\n",
    "    classes = tf.argmax(scores, axis=-1)\n",
    "    class_scores = tf.reduce_max(scores, axis=-1)\n",
    "\n",
    "    # Create mask for filtering\n",
    "    mask = class_scores >= thresh\n",
    "\n",
    "    # Apply mask\n",
    "    return tf.boolean_mask(class_scores, mask), tf.boolean_mask(boxes, mask), tf.boolean_mask(classes, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(b1, b2):\n",
    "    \"\"\"Compute the Intersection over Union (IoU) between two boxes.\"\"\"\n",
    "    \n",
    "    x1, y1, x2, y2 = b1\n",
    "    x1_, y1_, x2_, y2_ = b2\n",
    "\n",
    "    # Compute intersection\n",
    "    xi1, yi1 = max(x1, x1_), max(y1, y1_)\n",
    "    xi2, yi2 = min(x2, x2_), min(y2, y2_)\n",
    "    inter_w, inter_h = max(0, yi2 - yi1), max(0, xi2 - xi1)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    # Compute union\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x2_ - x1_) * (y2_ - y1_)\n",
    "    union_area = area1 + area2 - inter_area\n",
    "\n",
    "    return inter_area / union_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def yolo_nms(scores, boxes, classes, max_boxes=10, iou_thresh=0.5):\n",
    "    \"\"\"Applies Non-Max Suppression (NMS) to filter boxes.\"\"\"\n",
    "    \n",
    "    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')\n",
    "\n",
    "    # Get indices of boxes to keep\n",
    "    nms_idx = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_thresh)\n",
    "\n",
    "    # Select filtered scores, boxes, and classes\n",
    "    return tf.gather(scores, nms_idx), tf.gather(boxes, nms_idx), tf.gather(classes, nms_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set both TensorFlow and NumPy seeds\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "def yolo_boxes_to_corners(xy, wh):\n",
    "    \"\"\"Convert YOLO box format (x, y, w, h) to (x1, y1, x2, y2)\"\"\"\n",
    "    min_corner = xy - (wh / 2)\n",
    "    max_corner = xy + (wh / 2)\n",
    "    return tf.concat([min_corner, max_corner], axis=-1)\n",
    "\n",
    "def scale_boxes(boxes, img_shape):\n",
    "    \"\"\"Rescale the YOLO boxes to the original image size.\"\"\"\n",
    "    height, width = tf.cast(img_shape[0], tf.float32), tf.cast(img_shape[1], tf.float32)\n",
    "    scale = tf.stack([width, height, width, height])\n",
    "    return boxes * scale\n",
    "\n",
    "# Generate YOLO outputs with fixed seed\n",
    "yolo_outputs = (\n",
    "    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4),\n",
    "    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4),\n",
    "    tf.random.normal([19, 19, 5, 1], mean=1, stddev=4),\n",
    "    tf.random.normal([19, 19, 5, 80], mean=1, stddev=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def yolo_eval(outputs, img_shape=(720, 1280), max_boxes=10, score_thresh=0.6, iou_thresh=0.5):\n",
    "    \"\"\"Converts YOLO model output to final filtered boxes, scores, and classes.\"\"\"\n",
    "    \n",
    "    box_xy, box_wh, box_conf, box_probs = outputs\n",
    "\n",
    "    # Convert boxes to corner coordinates\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "\n",
    "    # Apply score filtering\n",
    "    scores, boxes, classes = yolo_filter_boxes(boxes, box_conf, box_probs, score_thresh)\n",
    "\n",
    "    # Scale boxes to original image size\n",
    "    boxes = scale_boxes(boxes, img_shape)\n",
    "\n",
    "    # Apply non-max suppression\n",
    "    return yolo_nms(scores, boxes, classes, max_boxes, iou_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 152.68243\n",
      "boxes[2] = [ 1530.0006   -3760.4392     831.5534     -19.682007]\n",
      "classes[2] = 25\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "# Run YOLO evaluation\n",
    "scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "\n",
    "# Print results\n",
    "print(\"scores[2] =\", scores[2].numpy())\n",
    "print(\"boxes[2] =\", boxes[2].numpy())\n",
    "print(\"classes[2] =\", classes[2].numpy())\n",
    "print(\"scores.shape =\", scores.numpy().shape)\n",
    "print(\"boxes.shape =\", boxes.numpy().shape)\n",
    "print(\"classes.shape =\", classes.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(416, 416)):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image not found or corrupted: {image_path}\")\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    image = cv2.resize(image, target_size)  # Resize to YOLO input shape\n",
    "    image = image / 255.0  # Normalize to [0,1]\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_data(image_dir, label_dir, subset_size=None):\n",
    "    images, labels = [], []\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "\n",
    "    if subset_size:\n",
    "        image_files = image_files[:subset_size]  # Limit dataset size\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Skipping {image_file}: Cannot read image.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        images.append(image_path)\n",
    "\n",
    "        # Read label file\n",
    "        label_array = []\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:\n",
    "                        label_array.append([float(x) for x in parts])\n",
    "                    else:\n",
    "                        print(f\"Warning: Skipping incorrect label format in {label_path}\")\n",
    "\n",
    "        # Append labels with correct shape\n",
    "        labels.append(np.array(label_array, dtype=np.float32) if label_array else np.zeros((0, 5), dtype=np.float32))\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(416, 416, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "\n",
    "        Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "\n",
    "        Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.5),  # Reduce memory usage\n",
    "        Dense(20 * 5, activation=\"linear\"),  # Output: 20 boxes × 5 values each\n",
    "        Reshape((20, 5))\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(y_true, y_pred):\n",
    "    \"\"\"Ensures y_true and y_pred have the same shape before loss computation.\"\"\"\n",
    "    y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "    print(f\"DEBUG: y_true shape: {y_true.shape}, y_pred shape: {y_pred.shape}\")  # Debugging\n",
    "\n",
    "    # Ensure they have the same shape\n",
    "    y_true = tf.reshape(y_true, tf.shape(y_pred))\n",
    "\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))  # Basic MSE loss (modify for YOLO loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_labels(labels, max_boxes=20):\n",
    "    \"\"\"\n",
    "    Pads labels to ensure all samples have the same number of bounding boxes.\n",
    "    Each label should have shape (num_boxes, 5), and we pad it to (max_boxes, 5).\n",
    "    \"\"\"\n",
    "    padded_labels = np.zeros((max_boxes, 5))  # Default fill with zeros\n",
    "    num_boxes = min(len(labels), max_boxes)  # Avoid exceeding max_boxes\n",
    "    padded_labels[:num_boxes] = labels[:num_boxes]  # Copy existing boxes\n",
    "    return padded_labels\n",
    "\n",
    "def data_generator(images, labels, batch_size):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            try:\n",
    "                # Select a random image & label\n",
    "                idx = np.random.randint(0, len(images))\n",
    "                img_path = images[idx]\n",
    "                label_data = labels[idx]\n",
    "\n",
    "                # Load Image\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    print(f\"❌ Skipping {img_path} (Failed to load)\")\n",
    "                    continue  # Skip if image is invalid\n",
    "\n",
    "                # Resize & Normalize Image\n",
    "                image = cv2.resize(image, (416, 416))\n",
    "                image = image / 255.0  # Normalize\n",
    "\n",
    "                # Ensure labels have correct shape\n",
    "                label_data = pad_labels(label_data)\n",
    "\n",
    "                batch_images.append(image)\n",
    "                batch_labels.append(label_data)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error processing {img_path}: {e}\")\n",
    "                continue  # Skip faulty example\n",
    "\n",
    "        # Ensure we return a full batch\n",
    "        if len(batch_images) == batch_size:\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "DEBUG: y_true shape: (None, 20, 5), y_pred shape: (None, 20, 5)\n",
      "DEBUG: y_true shape: (None, 20, 5), y_pred shape: (None, 20, 5)\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 884ms/step - accuracy: 0.1900 - loss: 39.3255\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 873ms/step - accuracy: 0.2772 - loss: 3.8755\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 874ms/step - accuracy: 0.3111 - loss: 0.2221\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 866ms/step - accuracy: 0.3436 - loss: 0.1420\n",
      "Epoch 5/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 875ms/step - accuracy: 0.3428 - loss: 0.1355\n",
      "Epoch 6/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3753 - loss: 0.1582\n",
      "Epoch 7/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.4434 - loss: 0.1359\n",
      "Epoch 8/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.4432 - loss: 0.1707\n",
      "Epoch 9/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 876ms/step - accuracy: 0.4477 - loss: 0.1725\n",
      "Epoch 10/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 869ms/step - accuracy: 0.4020 - loss: 0.9058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Training Complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "image_dir = r\"C:\\Users\\user\\Downloads\\archive\\vehicle dataset\\train\\images\"\n",
    "label_dir = r\"C:\\Users\\user\\Downloads\\archive\\vehicle dataset\\train\\labels\"\n",
    "images, labels = load_data(image_dir, label_dir, subset_size=500)\n",
    "\n",
    "# Initialize Data Generator\n",
    "batch_size = 8\n",
    "train_gen = data_generator(images, labels, batch_size)\n",
    "\n",
    "# Create Model\n",
    "model = yolo_model()\n",
    "model.compile(optimizer=Adam(), loss=yolo_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(train_gen, steps_per_epoch=len(images) // batch_size, epochs=10)\n",
    "\n",
    "# Save Model\n",
    "model.save(\"yolo_trained_model.h5\")\n",
    "print(\"✅ Model Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
